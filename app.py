import streamlit as st
from dataclasses import dataclass
from typing import List, Optional

# ===============================
# 1. MAPPINGS
# ===============================

CONSONANT_ONSET = {
    # single consonants
    "kh": "à¸‚", "k":  "à¸", "ph": "à¸œ", "p":  "à¸›",
    "th": "à¸–", "t":  "à¸•", "ch": "à¸Š", "c":  "à¸ˆ",
    "j":  "à¸ˆ", "b":  "à¸š", "d":  "à¸”", "f":  "à¸Ÿ",
    "s":  "à¸ª", "h":  "à¸«", "m":  "à¸¡", "n":  "à¸™",
    "ng": "à¸‡", "r":  "à¸£", "l":  "à¸¥", "w":  "à¸§",
    "y":  "à¸¢", "?":  "à¸­",
    # clusters
    "pr": "à¸›à¸£", "phr":"à¸žà¸£", "kr": "à¸à¸£", "khr":"à¸„à¸£", "tr": "à¸•à¸£",
    "pl": "à¸›à¸¥", "phl":"à¸žà¸¥", "kl": "à¸à¸¥", "khl":"à¸„à¸¥", "kw": "à¸à¸§", "khw":"à¸‚à¸§",
    # h-leading
    "hng":"à¸«à¸‡", "hn": "à¸«à¸™", "hm": "à¸«à¸¡", "hy": "à¸«à¸¢", "hr": "à¸«à¸£", "hl": "à¸«à¸¥", "hw": "à¸«à¸§",
}
ONSET_KEYS = sorted(CONSONANT_ONSET.keys(), key=len, reverse=True)

ALT_ONSET_FORMS = {
    "th": ["à¸–", "à¸—", "à¸˜", "à¸’", "à¸"],
    "ph": ["à¸œ", "à¸ž", "à¸ "],
    "ch": ["à¸Š", "à¸‰", "à¸Œ"],
    "s":  ["à¸ª", "à¸‹", "à¸¨", "à¸©"],
    "h":  ["à¸«", "à¸®"],
    "y":  ["à¸¢", "à¸"],
    "f":  ["à¸Ÿ", "à¸"],
    "k":  ["à¸", "à¹„à¸"], 
    "kh": ["à¸‚", "à¸„", "à¸†"],
    "d":  ["à¸”", "à¸Ž"],
    "t":  ["à¸•", "à¸"],
    "n":  ["à¸™", "à¸“"],
    "l":  ["à¸¥", "à¸¬"],
}

ALT_CODA_FORMS = {
    "n":  ["à¸™", "à¸£", "à¸¥", "à¸", "à¸“", "à¸¬", "à¸£à¸¢à¹Œ"], 
    "t":  ["à¸”", "à¸•", "à¸—", "à¸˜", "à¸¨", "à¸©", "à¸ª", "à¸ˆ", "à¸Š", "à¸‹", "à¸Ž", "à¸", "à¸", "à¸‘", "à¸’", "à¸•à¸´", "à¸•à¸¸", "à¸•à¸§à¹Œ"],
    "p":  ["à¸š", "à¸›", "à¸ž", "à¸Ÿ", "à¸ ", "à¸žà¸˜à¹Œ"],
    "k":  ["à¸", "à¸‚", "à¸„", "à¸†", "à¸„à¸£à¹Œ"],
}

VOWEL_MAP = {
    "a":  ("",  "",   "à¸°"), "aa": ("",  "",   "à¸²"),
    "i":  ("",  "à¸´",  ""),  "ii": ("",  "à¸µ",  ""),
    "u":  ("",  "à¸¸",  ""),  "uu": ("",  "à¸¹",  ""),
    "e":  ("à¹€", "à¹‡",  ""),  "ee": ("à¹€", "",   ""), 
    "o":  ("à¹‚", "",   "à¸°"), "oo": ("à¹‚", "",   ""), 
    "ae": ("à¹", "",   "à¸°"), "aee":("à¹", "",   ""),
    "ea": ("à¹", "",   "à¸°"), "eaa":("à¹", "",   ""),
    "oe": ("à¹€", "",   "à¸­à¸°"),"oee":("à¹€", "",   "à¸­"),
    "err":("à¹€", "",   "à¸­à¸°"),"er": ("à¹€", "",   "à¸­"),
    "or": ("à¹€", "",   "à¸²à¸°"),"orr":("",  "",   "à¸­"),
    "ia": ("à¹€", "à¸µ",  "à¸¢"), "ua": ("", "à¸±",  "à¸§"),
    "ai": ("à¹„", "",   ""),  "ay": ("à¹„", "",   ""), 
    "aw": ("à¹€", "",   "à¸²"), "uea":("à¹€", "à¸·", "à¸­"),
    "am": ("", "",   "à¸³"),    
}
VOWEL_KEYS = sorted(VOWEL_MAP.keys(), key=len, reverse=True)

TONE_MAP = {"1": "", "2": "à¹ˆ", "3": "à¹‰", "4": "à¹Š", "5": "à¹‹"}
CODA_MAP = {"ng": "à¸‡", "k": "à¸", "t": "à¸”", "p": "à¸š", "m": "à¸¡", "n": "à¸™", "w": "à¸§", "y": "à¸¢"}
CODA_KEYS = sorted(CODA_MAP.keys(), key=len, reverse=True)

# ===============================
# 2. CORE CONVERSION
# ===============================

def split_tone(s: str):
    if s and s[-1] in TONE_MAP: return s[:-1], TONE_MAP[s[-1]]
    return s, ""

def match_prefix(keys, s):
    for k in keys:
        if s.startswith(k): return k, s[len(k):]
    return "", s

def match_vowel(s):
    for v in VOWEL_KEYS:
        idx = s.find(v)
        if idx != -1: return v, s[:idx], s[idx+len(v):]
    return "", s, ""

def match_coda(s):
    for k in CODA_KEYS:
        if s.endswith(k): return k, s[:-len(k)]
    return "", s

def assemble(onset_thai: str, vowel_key: str, tone: str) -> str:
    onset_thai = onset_thai or "à¸"
    pre, main, post = VOWEL_MAP[vowel_key]
    if len(onset_thai) > 1:
        return pre + onset_thai[0] + onset_thai[1] + main + tone + post
    return pre + onset_thai + main + tone + post

def convert_syllable(roman: str) -> Optional[str]:
    roman = roman.lower()
    if not roman: return ""

    core, tone = split_tone(roman)
    vowel_key, before, after = match_vowel(core)
    
    if not vowel_key:
        onset_key, remainder = match_prefix(ONSET_KEYS, core)
        if remainder: return None
        onset_thai = CONSONANT_ONSET.get(onset_key, "")
        if len(onset_thai) > 1: return onset_thai[0] + onset_thai[1] + tone
        return onset_thai + tone

    onset_key, _ = match_prefix(ONSET_KEYS, before)
    onset_thai = CONSONANT_ONSET.get(onset_key, "")
    coda_key, _ = match_coda(after)
    coda_thai = CODA_MAP.get(coda_key, "")

    if vowel_key == "o" and coda_thai:
        onset_thai = onset_thai or "à¸"
        if len(onset_thai) > 1: return onset_thai[0] + onset_thai[1] + tone + coda_thai
        return onset_thai + tone + coda_thai

    if vowel_key == "a" and coda_thai:
        onset_thai = onset_thai or "à¸"
        if len(onset_thai) > 1: return onset_thai[0] + onset_thai[1] + "à¸±" + tone + coda_thai
        return onset_thai + "à¸±" + tone + coda_thai

    if vowel_key in ("er", "oee") and coda_thai in {"à¸¡", "à¸™", "à¸‡"}:
        onset_thai = onset_thai or "à¸"
        if len(onset_thai) > 1: return "à¹€" + onset_thai[0] + onset_thai[1] + "à¸´" + tone + coda_thai
        return "à¹€" + onset_thai + "à¸´" + tone + coda_thai

    return assemble(onset_thai, vowel_key, tone) + coda_thai

def recursive_split(roman: str) -> Optional[str]:
    if not roman: return ""
    for i in range(len(roman), 1, -1):
        prefix = roman[:i]
        res = convert_syllable(prefix)
        if res:
            remainder = roman[i:]
            if not remainder: return res
            rem_res = recursive_split(remainder)
            if rem_res: return res + rem_res
    return None

# ===============================
# 3. DICTIONARY
# ===============================

@dataclass
class DictEntry:
    roman: str
    thai: str
    freq: int = 1

BASE_DICTIONARY = [
    DictEntry("khon3", "à¸„à¸™", 100), DictEntry("khoon3", "à¸„à¸¸à¸“", 90),
    DictEntry("khao3", "à¹€à¸‚à¸²", 80), DictEntry("baan3", "à¸šà¹‰à¸²à¸™", 95),
    DictEntry("di1", "à¸”à¸µ", 85), DictEntry("phuean3", "à¹€à¸žà¸·à¹ˆà¸­à¸™", 90),
    DictEntry("er", "à¹€à¸­à¸­", 120), DictEntry("err", "à¹€à¸­à¸­à¸°", 110),
    DictEntry("dern", "à¹€à¸”à¸´à¸™", 200),
]

COMPOUND_WORDS = [
    DictEntry("khanom",   "à¸‚à¸™à¸¡",     500),
    DictEntry("?aacaan",  "à¸­à¸²à¸ˆà¸²à¸£à¸¢à¹Œ", 500),
    DictEntry("aacaan",   "à¸­à¸²à¸ˆà¸²à¸£à¸¢à¹Œ", 500),
    DictEntry("ajarn",    "à¸­à¸²à¸ˆà¸²à¸£à¸¢à¹Œ", 500),
    DictEntry("?aahaan",  "à¸­à¸²à¸«à¸²à¸£",   500),
    DictEntry("aahaan",   "à¸­à¸²à¸«à¸²à¸£",   500),
    DictEntry("?arory",   "à¸­à¸£à¹ˆà¸­à¸¢",   500),
    DictEntry("arory",    "à¸­à¸£à¹ˆà¸­à¸¢",   500),
    DictEntry("aroy",     "à¸­à¸£à¹ˆà¸­à¸¢",   450), 
    DictEntry("aroi",     "à¸­à¸£à¹ˆà¸­à¸¢",   450),
    DictEntry("phuying",  "à¸œà¸¹à¹‰à¸«à¸à¸´à¸‡",  500),
    DictEntry("sawatdii", "à¸ªà¸§à¸±à¸ªà¸”à¸µ",  1000),
    DictEntry("sabay",    "à¸ªà¸šà¸²à¸¢",    400),
    DictEntry("sanuk",    "à¸ªà¸™à¸¸à¸",    400),
    DictEntry("sanam",    "à¸ªà¸™à¸²à¸¡",    300),
    DictEntry("arak",     "à¸­à¸£à¸±à¸à¸©à¹Œ",  300),
    DictEntry("talaat",   "à¸•à¸¥à¸²à¸”",    300),
    DictEntry("thalay",   "à¸—à¸°à¹€à¸¥",    300),
    DictEntry("welaa",    "à¹€à¸§à¸¥à¸²",    300),
    DictEntry("naka",     "à¸™à¸°à¸„à¸°",    300),
    DictEntry("khrap",    "à¸„à¸£à¸±à¸š",    300),
    # Pseudo-clusters
    DictEntry("sabaay",   "à¸ªà¸šà¸²à¸¢",    400),
    DictEntry("sadaeng",  "à¹à¸ªà¸”à¸‡",    350),
    DictEntry("sathaanii","à¸ªà¸–à¸²à¸™à¸µ",   350),
    DictEntry("satrii",   "à¸ªà¸•à¸£à¸µ",    300),
    DictEntry("thanon",   "à¸–à¸™à¸™",     450),
    DictEntry("samut",    "à¸ªà¸¡à¸¸à¸”",    350),
    DictEntry("samoe",    "à¹€à¸ªà¸¡à¸­",    350),
    DictEntry("sanaam",   "à¸ªà¸™à¸²à¸¡",    350),
    DictEntry("chalaat",  "à¸‰à¸¥à¸²à¸”",    350),
    DictEntry("phanaek",  "à¹à¸œà¸™à¸",    300),
    DictEntry("chalaam",  "à¸‰à¸¥à¸²à¸¡",    300),
    DictEntry("khaya",    "à¸‚à¸¢à¸°",     300),
    DictEntry("sara",     "à¸ªà¸£à¸°",     300),
    DictEntry("sataem",   "à¸ªà¹à¸•à¸¡à¸›à¹Œ",  250),
    DictEntry("khamooy",   "à¸‚à¹‚à¸¡à¸¢",    350),
    DictEntry("samaakhom", "à¸ªà¸¡à¸²à¸„à¸¡",   300),
    DictEntry("samaachik", "à¸ªà¸¡à¸²à¸Šà¸´à¸",   300),
    DictEntry("samaathi",  "à¸ªà¸¡à¸²à¸˜à¸´",    300),
]

AI_IRREGULARS = [
    DictEntry("cay", "à¹ƒà¸ˆ", 200), DictEntry("khray", "à¹ƒà¸„à¸£", 200),
    DictEntry("may", "à¹ƒà¸«à¸¡à¹ˆ", 200), DictEntry("hay", "à¹ƒà¸«à¹‰", 200),
    DictEntry("chay", "à¹ƒà¸Šà¹ˆ", 200),
]

VOWEL_SUGGESTIONS = [
    DictEntry("a", "à¸­à¸°", 150), DictEntry("a", "à¸­à¸²", 140),
    DictEntry("ai", "à¹„à¸­", 130), DictEntry("ay", "à¹„à¸­", 130),
]

DICTIONARY = BASE_DICTIONARY + COMPOUND_WORDS + AI_IRREGULARS + VOWEL_SUGGESTIONS
DICT_LOOKUP = {e.roman.lower(): e.thai for e in DICTIONARY}

def convert_token(token: str) -> str:
    token = token.lower()
    if token in DICT_LOOKUP: return DICT_LOOKUP[token]
    syl = convert_syllable(token)
    if syl: return syl
    compound = recursive_split(token)
    if compound: return compound
    return "?"

def convert_phrase(text: str) -> str:
    """Converts a full phrase/sentence by splitting on spaces."""
    return " ".join(convert_token(t) for t in text.split())

def alt_onset_suggestions(buffer):
    roman = buffer.lower()
    core, _ = split_tone(roman)
    vowel_key, before, after = match_vowel(core)
    if not vowel_key and not before: roman_onset, _ = match_prefix(ONSET_KEYS, core)
    else: roman_onset, _ = match_prefix(ONSET_KEYS, before)
    if roman_onset not in ALT_ONSET_FORMS: return []
    default_thai = CONSONANT_ONSET.get(roman_onset, "")
    base_thai = convert_token(buffer)
    if not base_thai or base_thai == "?": return []
    alts = []
    for alt in ALT_ONSET_FORMS[roman_onset]:
        if alt == default_thai: continue
        thai_form = base_thai.replace(default_thai, alt, 1)
        alts.append(DictEntry(roman=buffer, thai=thai_form, freq=40))
    return alts

def alt_coda_suggestions(buffer):
    roman = buffer.lower()
    core, _ = split_tone(roman)
    vowel_key, _, after = match_vowel(core)
    if not vowel_key: return [] 
    coda_key, _ = match_coda(after)
    if coda_key not in ALT_CODA_FORMS: return []
    default_coda = CODA_MAP.get(coda_key, "")
    base_thai = convert_token(buffer)
    if not base_thai or base_thai == "?" or not base_thai.endswith(default_coda): return []
    base_stem = base_thai[: -len(default_coda)]
    alts = []
    for alt in ALT_CODA_FORMS[coda_key]:
        if alt == default_coda: continue
        alts.append(DictEntry(roman=buffer, thai=base_stem + alt, freq=35))
    return alts

def suggest(buffer: str, max_suggestions: int = 8) -> List[DictEntry]:
    q = buffer.lower()
    if not q: return []
    q_core = q[:-1] if q[-1] in "12345" else q
    exact_prefix = [e for e in DICTIONARY if e.roman.startswith(q_core)]
    def simple_distance(a, b):
        n = min(len(a), len(b))
        diff = sum(a[i] != b[i] for i in range(n)) + abs(len(a) - len(b))
        return diff
    fuzzy = [e for e in DICTIONARY if 0 < simple_distance(q_core, e.roman) <= 1]
    seen = set()
    results = []
    def add(entries):
        for e in entries:
            key = (e.roman, e.thai)
            if key not in seen:
                seen.add(key); results.append(e)
    # Add base conversion first if valid
    base_val = convert_token(q)
    if base_val and base_val != "?":
        add([DictEntry(q, base_val, 999)])
    add(exact_prefix)
    add(fuzzy)
    add(alt_onset_suggestions(buffer))
    add(alt_coda_suggestions(buffer))
    results.sort(key=lambda e: e.freq, reverse=True)
    return results[:max_suggestions]

# ===============================
# 4. STREAMLIT UI
# ===============================

st.set_page_config(page_title="Thai IME", page_icon="ðŸ‡¹ðŸ‡­", layout="centered")

# --- SESSION STATE INITIALIZATION ---
if 'draft_text' not in st.session_state:
    st.session_state['draft_text'] = ""
if 'last_roman' not in st.session_state:
    st.session_state['last_roman'] = ""

def append_word(word):
    """Appends word to draft text"""
    if st.session_state.draft_text:
        st.session_state.draft_text += " " + word
    else:
        st.session_state.draft_text = word

def submit_input():
    """Callback: commits input to draft, stores for suggestions, and clears input"""
    roman = st.session_state.input_text
    if roman:
        # 1. Convert
        thai_word = convert_phrase(roman)
        # 2. Append to Draft
        append_word(thai_word)
        # 3. Save for suggestions display
        st.session_state.last_roman = roman
        # 4. Clear Input
        st.session_state.input_text = ""

# --- SIDEBAR: CHEAT SHEET (3 SECTIONS) ---
with st.sidebar:
    st.title("Cheat Sheet ðŸ“–")
    
    with st.expander("1. Vowels", expanded=True):
        st.markdown("""
        | Roman | Pre | Stack | Post | Ex. (k) |
        | :--- | :---: | :---: | :---: | :--- |
        | **a** | - | - | à¸° | à¸à¸° |
        | **aa** | - | - | à¸² | à¸à¸² |
        | **i** | - | à¸´ | - | à¸à¸´ |
        | **ii** | - | à¸µ | - | à¸à¸µ |
        | **u** | - | à¸¸ | - | à¸à¸¸ |
        | **uu** | - | à¸¹ | - | à¸à¸¹ |
        | **e** | à¹€ | à¹‡ | - | à¹€à¸à¹‡à¸™ |
        | **ee** | à¹€ | - | - | à¹€à¸ |
        | **o** | à¹‚ | - | à¸° | à¹‚à¸à¸° |
        | **oo** | à¹‚ | - | - | à¹‚à¸ |
        | **ae** | à¹ | - | à¸° | à¹à¸à¸° |
        | **aee** | à¹ | - | - | à¹à¸ |
        | **oe** | à¹€ | - | à¸­à¸° | à¹€à¸à¸­à¸° |
        | **or** | à¹€ | - | à¸²à¸° | à¹€à¸à¸²à¸° |
        | **ia** | à¹€ | à¸µ | à¸¢ | à¹€à¸à¸µà¸¢ |
        | **ua** | - | à¸± | à¸§ | à¸à¸±à¸§ |
        | **ai** | à¹„ | - | - | à¹„à¸ |
        | **aw** | à¹€ | - | à¸² | à¹€à¸à¸² |
        | **uea** | à¹€ | à¸· | à¸­ | à¹€à¸à¸·à¸­ |
        | **am** | - | - | à¸³ | à¸à¸³ |
        """)

    with st.expander("2. Consonants & Tones"):
        st.markdown("""
        **Consonants**
        * `k` = à¸, `kh` = à¸‚
        * `p` = à¸›, `ph` = à¸œ
        * `t` = à¸•, `th` = à¸–
        * `ng` = à¸‡, `ch` = à¸Š
        
        **Tones**
        * `1` = Mid, `2` = Low (à¹ˆ)
        * `3` = Falling (à¹‰), `4` = High (à¹Š)
        * `5` = Rising (à¹‹)
        """)

    with st.expander("3. Tips & Compounds"):
        st.markdown("""
        **Typing Tips**
        * **Enter Key**: Commits the word and clears the input box.
        * **Suggestions**: Appear *after* you hit Enter (based on what you just added).
        """)

# --- MAIN PAGE ---
st.title("ðŸ‡¹ðŸ‡­ Thai Word Converter")

# 1. Result Text
st.markdown("##### Result Text")
st.text_area(
    label="Result",
    key="draft_text",
    height=100,
    label_visibility="collapsed"
)

# 2. Roman Input
st.markdown("##### Enter Romanized Thai")
st.text_input(
    label="Input", 
    key="input_text", # Linked to session state
    placeholder="Type (e.g., sabaay) and hit ENTER to add...",
    label_visibility="collapsed",
    on_change=submit_input # Triggers commit & clear on Enter
)

# 3. Suggestions (Based on LAST submitted word)
if st.session_state.last_roman:
    suggestions = suggest(st.session_state.last_roman)
    if suggestions:
        st.markdown(f"**Alternatives for:** `{st.session_state.last_roman}`")
        cols = st.columns(4)
        for i, s in enumerate(suggestions):
            with cols[i % 4]:
                st.button(
                    f"{s.thai}\n({s.roman})", 
                    key=f"btn_{i}", 
                    on_click=append_word, 
                    args=(s.thai,)
                )