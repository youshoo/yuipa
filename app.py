import streamlit as st
from dataclasses import dataclass
from typing import List, Optional

# ===============================
# 1. MAPPINGS & DATA
# ===============================

CONSONANT_ONSET = {
    # single consonants
    "kh": "à¸‚", "k":  "à¸", "ph": "à¸œ", "p":  "à¸›",
    "th": "à¸–", "t":  "à¸•", "ch": "à¸Š", "c":  "à¸ˆ",
    "j":  "à¸ˆ", "b":  "à¸š", "d":  "à¸”", "f":  "à¸Ÿ",
    "s":  "à¸ª", "h":  "à¸«", "m":  "à¸¡", "n":  "à¸™",
    "ng": "à¸‡", "r":  "à¸£", "l":  "à¸¥", "w":  "à¸§",
    "y":  "à¸¢", "?":  "à¸­",
    # clusters
    "pr": "à¸›à¸£", "phr":"à¸žà¸£", "kr": "à¸à¸£", "khr":"à¸„à¸£", "tr": "à¸•à¸£",
    "pl": "à¸›à¸¥", "phl":"à¸žà¸¥", "kl": "à¸à¸¥", "khl":"à¸„à¸¥", "kw": "à¸à¸§", "khw":"à¸‚à¸§",
    # h-leading
    "hng":"à¸«à¸‡", "hn": "à¸«à¸™", "hm": "à¸«à¸¡", "hy": "à¸«à¸¢", "hr": "à¸«à¸£", "hl": "à¸«à¸¥", "hw": "à¸«à¸§",
}
ONSET_KEYS = sorted(CONSONANT_ONSET.keys(), key=len, reverse=True)

ALT_ONSET_FORMS = {
    "th": ["à¸–", "à¸—", "à¸˜", "à¸’", "à¸"], "ph": ["à¸œ", "à¸ž", "à¸ "],
    "ch": ["à¸Š", "à¸‰", "à¸Œ"], "s":  ["à¸ª", "à¸‹", "à¸¨", "à¸©"],
    "h":  ["à¸«", "à¸®"], "y":  ["à¸¢", "à¸"], "f":  ["à¸Ÿ", "à¸"],
    "k":  ["à¸", "à¹„à¸"], "kh": ["à¸‚", "à¸„", "à¸†"], "d":  ["à¸”", "à¸Ž"],
    "t":  ["à¸•", "à¸"], "n":  ["à¸™", "à¸“"], "l":  ["à¸¥", "à¸¬"],
}

ALT_CODA_FORMS = {
    "n":  ["à¸™", "à¸£", "à¸¥", "à¸", "à¸“", "à¸¬", "à¸£à¸¢à¹Œ"], 
    "t":  ["à¸”", "à¸•", "à¸—", "à¸˜", "à¸¨", "à¸©", "à¸ª", "à¸ˆ", "à¸Š", "à¸‹", "à¸Ž", "à¸", "à¸", "à¸‘", "à¸’", "à¸•à¸´", "à¸•à¸¸", "à¸•à¸§à¹Œ"],
    "p":  ["à¸š", "à¸›", "à¸ž", "à¸Ÿ", "à¸ ", "à¸žà¸˜à¹Œ"],
    "k":  ["à¸", "à¸‚", "à¸„", "à¸†", "à¸„à¸£à¹Œ"],
}

VOWEL_MAP = {
    "a":  ("",  "",   "à¸°"), "aa": ("",  "",   "à¸²"),
    "i":  ("",  "à¸´",  ""),  "ii": ("",  "à¸µ",  ""),
    "u":  ("",  "à¸¸",  ""),  "uu": ("",  "à¸¹",  ""),
    "e":  ("à¹€", "à¹‡",  ""),  "ee": ("à¹€", "",   ""), 
    "o":  ("à¹‚", "",   "à¸°"), "oo": ("à¹‚", "",   ""), 
    "ae": ("à¹", "",   "à¸°"), "aee":("à¹", "",   ""),
    "ea": ("à¹", "",   "à¸°"), "eaa":("à¹", "",   ""),    
    "oe": ("à¹€", "",   "à¸­à¸°"),"oee":("à¹€", "",   "à¸­"),
    "err":("à¹€", "",   "à¸­à¸°"),"er": ("à¹€", "",   "à¸­"),
    "or": ("à¹€", "",   "à¸²à¸°"),"orr":("",  "",   "à¸­"),
    "ia": ("à¹€", "à¸µ",  "à¸¢"), "ua": ("", "à¸±",  "à¸§"),    
    "ai": ("à¹„", "",   ""),  "ay": ("à¹„", "",   ""), 
    "aw": ("à¹€", "",   "à¸²"), "uea":("à¹€", "à¸·", "à¸­"),    
    "am": ("", "",   "à¸³"),    
}
VOWEL_KEYS = sorted(VOWEL_MAP.keys(), key=len, reverse=True)

TONE_MAP = {"1": "Mid", "2": "à¹ˆ (Low)", "3": "à¹‰ (Falling)", "4": "à¹Š (High)", "5": "à¹‹ (Rising)"}
CODA_MAP = {"ng": "à¸‡", "k": "à¸", "t": "à¸”", "p": "à¸š", "m": "à¸¡", "n": "à¸™", "w": "à¸§", "y": "à¸¢"}
CODA_KEYS = sorted(CODA_MAP.keys(), key=len, reverse=True)

# ===============================
# 2. CORE CONVERSION LOGIC
# ===============================

def split_tone(s: str):
    # Map back to simple char for processing
    t_map = {"1": "", "2": "à¹ˆ", "3": "à¹‰", "4": "à¹Š", "5": "à¹‹"}
    if s and s[-1] in t_map: return s[:-1], t_map[s[-1]]
    return s, ""

def match_prefix(keys, s):
    for k in keys:
        if s.startswith(k): return k, s[len(k):]
    return "", s

def match_vowel(s):
    for v in VOWEL_KEYS:
        idx = s.find(v)
        if idx != -1: return v, s[:idx], s[idx+len(v):]
    return "", s, ""

def match_coda(s):
    for k in CODA_KEYS:
        if s.endswith(k): return k, s[:-len(k)]
    return "", s

def assemble(onset_thai: str, vowel_key: str, tone: str) -> str:
    onset_thai = onset_thai or "à¸"
    pre, main, post = VOWEL_MAP[vowel_key]
    if len(onset_thai) > 1:
        c1, c2 = onset_thai[0], onset_thai[1]
        return pre + c1 + c2 + main + tone + post
    return pre + onset_thai + main + tone + post

def convert_syllable(roman: str) -> Optional[str]:
    roman = roman.lower()
    if not roman: return ""

    core, tone = split_tone(roman)
    vowel_key, before, after = match_vowel(core)
    
    if not vowel_key:
        onset_key, remainder = match_prefix(ONSET_KEYS, core)
        if remainder: return None
        onset_thai = CONSONANT_ONSET.get(onset_key, "")
        if len(onset_thai) > 1: return onset_thai[0] + onset_thai[1] + tone
        return onset_thai + tone

    onset_key, _ = match_prefix(ONSET_KEYS, before)
    onset_thai = CONSONANT_ONSET.get(onset_key, "")
    coda_key, _ = match_coda(after)
    coda_thai = CODA_MAP.get(coda_key, "")

    # Rules
    if vowel_key == "o" and coda_thai:
        onset_thai = onset_thai or "à¸"
        if len(onset_thai) > 1: return onset_thai[0] + onset_thai[1] + tone + coda_thai
        return onset_thai + tone + coda_thai
    if vowel_key == "a" and coda_thai:
        onset_thai = onset_thai or "à¸"
        if len(onset_thai) > 1: return onset_thai[0] + onset_thai[1] + "à¸±" + tone + coda_thai
        return onset_thai + "à¸±" + tone + coda_thai
    if vowel_key in ("er", "oee") and coda_thai in {"à¸¡", "à¸™", "à¸‡"}:
        onset_thai = onset_thai or "à¸"
        if len(onset_thai) > 1: return "à¹€" + onset_thai[0] + onset_thai[1] + "à¸´" + tone + coda_thai
        return "à¹€" + onset_thai + "à¸´" + tone + coda_thai

    return assemble(onset_thai, vowel_key, tone) + coda_thai

def recursive_split(roman: str) -> Optional[str]:
    if not roman: return ""
    for i in range(len(roman), 1, -1):
        prefix = roman[:i]
        res = convert_syllable(prefix)
        if res:
            remainder = roman[i:]
            if not remainder: return res
            rem_res = recursive_split(remainder)
            if rem_res: return res + rem_res
    return None

# ===============================
# 3. DICTIONARY
# ===============================

@dataclass
class DictEntry:
    roman: str
    thai: str
    freq: int = 1

BASE_DICTIONARY = [
    DictEntry("khon3", "à¸„à¸™", 100), DictEntry("khoon3", "à¸„à¸¸à¸“", 90),
    DictEntry("khao3", "à¹€à¸‚à¸²", 80), DictEntry("baan3", "à¸šà¹‰à¸²à¸™", 95),
    DictEntry("di1", "à¸”à¸µ", 85), DictEntry("phuean3", "à¹€à¸žà¸·à¹ˆà¸­à¸™", 90),
    DictEntry("er", "à¹€à¸­à¸­", 120), DictEntry("err", "à¹€à¸­à¸­à¸°", 110),
    DictEntry("dern", "à¹€à¸”à¸´à¸™", 200),
]

COMPOUND_WORDS = [
    DictEntry("khanom", "à¸‚à¸™à¸¡", 500), DictEntry("ajarn", "à¸­à¸²à¸ˆà¸²à¸£à¸¢à¹Œ", 500),
    DictEntry("?aacaan", "à¸­à¸²à¸ˆà¸²à¸£à¸¢à¹Œ", 500), DictEntry("aacaan", "à¸­à¸²à¸ˆà¸²à¸£à¸¢à¹Œ", 500),
    DictEntry("arory", "à¸­à¸£à¹ˆà¸­à¸¢", 500), DictEntry("aroy", "à¸­à¸£à¹ˆà¸­à¸¢", 450), 
    DictEntry("aroi", "à¸­à¸£à¹ˆà¸­à¸¢", 450), DictEntry("phuying", "à¸œà¸¹à¹‰à¸«à¸à¸´à¸‡", 500),
    DictEntry("sawatdii", "à¸ªà¸§à¸±à¸ªà¸”à¸µ", 1000), DictEntry("sabay", "à¸ªà¸šà¸²à¸¢", 400),
    DictEntry("sanuk", "à¸ªà¸™à¸¸à¸", 400), DictEntry("sanam", "à¸ªà¸™à¸²à¸¡", 300),
    # Pseudo-clusters
    DictEntry("sabaay", "à¸ªà¸šà¸²à¸¢", 400), DictEntry("sadaeng", "à¹à¸ªà¸”à¸‡", 350),
    DictEntry("sathaanii","à¸ªà¸–à¸²à¸™à¸µ", 350), DictEntry("satrii", "à¸ªà¸•à¸£à¸µ", 300),
    DictEntry("thanon", "à¸–à¸™à¸™", 450), DictEntry("samut", "à¸ªà¸¡à¸¸à¸”", 350),
    DictEntry("samoe", "à¹€à¸ªà¸¡à¸­", 350), DictEntry("sanaam", "à¸ªà¸™à¸²à¸¡", 350),
    DictEntry("chalaat", "à¸‰à¸¥à¸²à¸”", 350), DictEntry("phanaek", "à¹à¸œà¸™à¸", 300),
    DictEntry("chalaam", "à¸‰à¸¥à¸²à¸¡", 300), DictEntry("khaya", "à¸‚à¸¢à¸°", 300),
    DictEntry("sara", "à¸ªà¸£à¸°", 300), DictEntry("sataem", "à¸ªà¹à¸•à¸¡à¸›à¹Œ", 250),
    DictEntry("khamooy", "à¸‚à¹‚à¸¡à¸¢", 350), DictEntry("samaakhom", "à¸ªà¸¡à¸²à¸„à¸¡", 300),
    DictEntry("samaachik", "à¸ªà¸¡à¸²à¸Šà¸´à¸", 300), DictEntry("samaathi", "à¸ªà¸¡à¸²à¸˜à¸´", 300),
]

AI_IRREGULARS = [
    DictEntry("cay", "à¹ƒà¸ˆ", 200), DictEntry("khray", "à¹ƒà¸„à¸£", 200),
    DictEntry("may", "à¹ƒà¸«à¸¡à¹ˆ", 200), DictEntry("hay", "à¹ƒà¸«à¹‰", 200),
    DictEntry("chay", "à¹ƒà¸Šà¹ˆ", 200),
]

DICTIONARY = BASE_DICTIONARY + COMPOUND_WORDS + AI_IRREGULARS
DICT_LOOKUP = {e.roman.lower(): e.thai for e in DICTIONARY}

def convert_token(token: str) -> str:
    token = token.lower()
    if token in DICT_LOOKUP: return DICT_LOOKUP[token]
    syl = convert_syllable(token)
    if syl: return syl
    compound = recursive_split(token)
    if compound: return compound
    return "?"

def convert_phrase(text: str) -> str:
    return " ".join(convert_token(t) for t in text.split())

def simple_distance(a, b):
    a, b = a.lower(), b.lower()
    if abs(len(a) - len(b)) > 2: return 999
    n = min(len(a), len(b))
    diff = sum(a[i] != b[i] for i in range(n))
    diff += abs(len(a) - len(b))
    return diff

def suggest(buffer: str, max_suggestions: int = 8) -> List[DictEntry]:
    q = buffer.lower()
    if not q: return []
    q_core = q[:-1] if q[-1] in "12345" else q
    exact_prefix = [e for e in DICTIONARY if e.roman.startswith(q_core)]
    fuzzy = [e for e in DICTIONARY if 0 < simple_distance(q_core, e.roman) <= 1]
    
    seen = set()
    results = []
    def add(entries):
        for e in entries:
            key = (e.roman, e.thai)
            if key not in seen:
                seen.add(key); results.append(e)
    add(exact_prefix)
    add(fuzzy)
    results.sort(key=lambda e: e.freq, reverse=True)
    return results[:max_suggestions]

# ===============================
# 4. STREAMLIT UI
# ===============================

st.set_page_config(page_title="Thai IME Tester", page_icon="ðŸ‡¹ðŸ‡­")

st.title("ðŸ‡¹ðŸ‡­ Thai Phonetic IME")
st.markdown("Type Romanized Thai (e.g., *sawatdii*, *khanom*, *thaaw2*) to see the conversion.")

# --- CHEAT SHEET SECTION ---
with st.expander("ðŸ“– Cheat Sheet & Instructions (How to Type)"):
    tab1, tab2, tab3 = st.tabs(["Tone Mappings", "Consonant Onsets", "Vowels"])
    
    with tab1:
        st.markdown("### Tone Numbers")
        st.markdown("Type these numbers at the end of a syllable.")
        tone_data = [{"Key": k, "Tone": v} for k, v in TONE_MAP.items()]
        st.table(tone_data)

    with tab2:
        st.markdown("### Initial Consonants")
        st.markdown("Sorted by length. Type the **Key** to get the **Thai Char**.")
        # Convert dictionary to list of dicts for display
        cons_data = [{"Key": k, "Thai Char": v} for k, v in CONSONANT_ONSET.items()]
        st.dataframe(cons_data, use_container_width=True)
    
    with tab3:
        st.markdown("### Vowels")
        st.markdown("Type the **Key** to get the vowel combination.")
        # Simplify Vowel Map for display (just showing key and components)
        vowel_disp = []
        for k, v in VOWEL_MAP.items():
            pre, main, post = v
            display_str = f"{pre} - {main} - {post}"
            vowel_disp.append({"Key": k, "Structure": display_str})
        st.dataframe(vowel_disp, use_container_width=True)

# --- MAIN APP ---
with st.container():
    roman_input = st.text_input("Roman Input:", placeholder="Type here... (e.g., sabaay, aroy, thaaw2)", key="input")

    if roman_input:
        # 1. Base Conversion
        base_thai = convert_phrase(roman_input)
        
        st.markdown("### Base Conversion")
        st.success(f"**{base_thai}**")

        # 2. Suggestions
        suggestions = suggest(roman_input)
        
        st.markdown("### Suggestions")
        if suggestions:
            cols = st.columns(3)
            for i, s in enumerate(suggestions):
                with cols[i % 3]:
                    st.button(f"{s.thai} ({s.roman})", key=f"sug_{i}")
        else:
            st.caption("No additional suggestions found.")

st.markdown("---")
st.caption("Tip: Check the Cheat Sheet above for Tones (1-5) and specific spellings.")